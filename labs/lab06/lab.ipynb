{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "dac1239f",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"lab.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79d52d2",
   "metadata": {},
   "source": [
    "# Lab 6 â€“ APIs and Web Scraping\n",
    "\n",
    "## DSC 80, Winter 2024\n",
    "\n",
    "### Due Date: Wednesday, February 21th at 5:00 PM <span style=\"color:red\">(no slip days!)</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e745313",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "\n",
    "Welcome to the sixth DSC 80 lab this quarter!\n",
    "\n",
    "Much like in DSC 10, this Jupyter Notebook contains the statements of the problems and provides code and Markdown cells to display your answers to the problems. Unlike DSC 10, the notebook is *only* for displaying a readable version of your final answers. The coding will be done in an accompanying `lab.py` file that is imported into the current notebook, and **you will only submit that `lab.py` file**, not this notebook!\n",
    "\n",
    "Some additional guidelines:\n",
    "- **Unlike in DSC 10, labs will have both public tests and hidden tests.** The bulk of your grade will come from your scores on hidden tests, which you will only see on Gradescope after the assignment deadline.\n",
    "- **Do not change the function names in the `lab.py` file!** The functions in the `lab.py` file are how your assignment is graded, and they are graded by their name. If you changed something you weren't supposed to, you can find the original code in the [course GitHub repository](https://github.com/dsc-courses/dsc80-2024-wi).\n",
    "- Notebooks are nice for testing and experimenting with different implementations before designing your function in your `lab.py` file. You can write code here, but make sure that all of your real work is in the `lab.py` file, since that's all you're submitting.\n",
    "- You are encouraged to write your own additional helper functions to solve the lab, as long as they also end up in `lab.py`.\n",
    "\n",
    "**To ensure that all of the work you want to submit is in `lab.py`, we've included a script named `lab-validation.py` in the lab folder. You shouldn't edit it, but instead, you should call it from the command line (e.g. the Terminal) to test your work.** More details on its usage are given at the bottom of this notebook.\n",
    "\n",
    "**Importing code from `lab.py`**:\n",
    "\n",
    "* Below, we import the `.py` file that's contained in the same directory as this notebook.\n",
    "* We use the `autoreload` notebook extension to make changes to our `lab.py` file immediately available in our notebook. Without this extension, we would need to restart the notebook kernel to see any changes to `lab.py` in the notebook.\n",
    "    - `autoreload` is necessary because, upon import, `lab.py` is compiled to bytecode (in the directory `__pycache__`). Subsequent imports of `lab` merely import the existing compiled python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "3dbb50b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete or Uncomment After Installing lxml\n",
    "#!pip install lxml==4.9.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "d91358d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "50fed607",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lab import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "af2c3c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import bs4\n",
    "import lxml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e516e22f",
   "metadata": {},
   "source": [
    "## Question 1 â€“ Practice with HTML Tags ðŸ“Ž\n",
    "\n",
    "In Question 2, you'll spend plenty of time parsing HTML source code. But before you get your hands dirty trying to extract information from HTML written by other people, it is a good idea to write basic HTML code yourself. This exercise will help you better understand how the code in a `.html` file is structured.\n",
    "\n",
    "For this question, you'll create a very basic `.html` file, named `lab06_1.html`, that satisfies the following conditions:\n",
    "\n",
    "- It must have `<title>` and `<head>` tags.\n",
    "- It must also have `<body>` tags. Within the `<body>` tags, it must have:\n",
    "    - At least two headers.\n",
    "    * At least three images.\n",
    "        - At least one image must be a local file.\n",
    "        - At least one image must be linked to online source.\n",
    "        - At least one image has to have default text when it cannot be displayed.\n",
    "    * At least three references (hyperlinks) to different web pages.\n",
    "    * At least one table with two rows and two columns.\n",
    "    \n",
    "\n",
    "Make sure to save your file as `lab06_1.html`, and save it in the same directory as `lab.py`. **When submitting this homework to Gradescope, make sure to also upload `lab06_1.html` along with the local image that you embedded in your site.** You can upload multiple files to Gradescope at a time.\n",
    "   \n",
    "\n",
    "***Notes***:\n",
    "- You can write and view basic HTML with a Jupyter Notebook, using either a Markdown cell or by using the `IPython.display.HTML` function (which takes in a string of HTML and renders it).\n",
    "- If you write your HTML code within a Jupyter Notebook, you should later copy your code into a text editor and save it with the `.html` extension. You could also write your HTML in a text editor directly.\n",
    "- Be sure to open your final `.html` file in a browser and make sure it looks correct on its own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df06eef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a042b560",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "8cb6040c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't delete this cell!\n",
    "question1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "798826eb",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q1</pre></strong> passed!</p>"
      ],
      "text/plain": [
       "q1 results: All test cases passed!"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1860e8",
   "metadata": {},
   "source": [
    "## Question 2 â€“ Scraping an Online Bookstore ðŸ“š\n",
    "\n",
    "Browse through the following fake online bookstore: http://books.toscrape.com/. This website is meant for toying with scraping.\n",
    "\n",
    "Your job is to scrape the website, collecting data on all books that have:\n",
    "- **_at least_ a four-star rating**, and\n",
    "- **a price _strictly_ less than Â£50**, and \n",
    "- **belong to specific categories** (more details below). \n",
    "\n",
    "You will extract the information into a DataFrame that looks like the one below.\n",
    "\n",
    "<table border=\"1\" class=\"dataframe\">\n",
    "  <thead>\n",
    "    <tr style=\"text-align: right;\">\n",
    "      <th></th>\n",
    "      <th>UPC</th>\n",
    "      <th>Product Type</th>\n",
    "      <th>Price (excl. tax)</th>\n",
    "      <th>Price (incl. tax)</th>\n",
    "      <th>Tax</th>\n",
    "      <th>Availability</th>\n",
    "      <th>Number of reviews</th>\n",
    "      <th>Category</th>\n",
    "      <th>Rating</th>\n",
    "      <th>Description</th>\n",
    "      <th>Title</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <th>0</th>\n",
    "      <td>e10e1e165dc8be4a</td>\n",
    "      <td>Books</td>\n",
    "      <td>Ã‚Â£22.60</td>\n",
    "      <td>Ã‚Â£22.60</td>\n",
    "      <td>Ã‚Â£0.00</td>\n",
    "      <td>In stock (19 available)</td>\n",
    "      <td>0</td>\n",
    "      <td>Default</td>\n",
    "      <td>Four</td>\n",
    "      <td>For readers of Laura Hillenbrand's Seabiscuit...</td>\n",
    "      <td>The Boys in the Boat: Nine Americans...</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>1</th>\n",
    "      <td>c2e46a2ee3b4a322</td>\n",
    "      <td>Books</td>\n",
    "      <td>Ã‚Â£25.27</td>\n",
    "      <td>Ã‚Â£25.27</td>\n",
    "      <td>Ã‚Â£0.00</td>\n",
    "      <td>In stock (19 available)</td>\n",
    "      <td>0</td>\n",
    "      <td>Romance</td>\n",
    "      <td>Five</td>\n",
    "      <td>A Michelin two-star chef at twenty-eight, Violette...</td>\n",
    "      <td>Chase Me (Paris Nights #2)</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>2</th>\n",
    "      <td>00bfed9e18bb36f3</td>\n",
    "      <td>Books</td>\n",
    "      <td>Ã‚Â£34.53</td>\n",
    "      <td>Ã‚Â£34.53</td>\n",
    "      <td>Ã‚Â£0.00</td>\n",
    "      <td>In stock (19 available)</td>\n",
    "      <td>0</td>\n",
    "      <td>Romance</td>\n",
    "      <td>Five</td>\n",
    "      <td>No matter how busy he keeps himself...</td>\n",
    "      <td>Black Dust</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "\n",
    "To do so, implement the following functions.\n",
    "\n",
    "<br>\n",
    "\n",
    "#### `extract_book_links`\n",
    "\n",
    "Complete the implementation of the function `extract_book_links`, which takes in the content of a page that contains book listings as a **string of HTML**, and returns a **list** of URLs of book-specific pages for all books with **_at least_ a four-star rating and a price _strictly_ less than Â£50**. \n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "#### `get_product_info`\n",
    "\n",
    "Complete the implementation of the function `get_product_info`, which takes in the content of a book-specific page as a **string of HTML**, and a list `categories` of book categories. If the input book is in the list of `categories`, `get_product_info` should return a dictionary corresponding to a row in the DataFrame in the image above (where the keys are the column names and the values are the row values). If the input book is not in the list of `categories`, return `None`.\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "#### `scrape_books`\n",
    "\n",
    "Finally, put everything together. Complete the implementation of the function `scrape_books`, which takes in an integer `k` and a list `categories` of book categories. `scrape_books` should use `requests` to scrape the first `k` pages of the bookstore and return a DataFrame of only the books that have \n",
    "- **_at least_ a four-star rating**, and\n",
    "- **a price _strictly_ less than Â£50**, and\n",
    "- **a category that is in the list `categories`**.\n",
    "\n",
    "<br>\n",
    "\n",
    "Some general guidance and tips:\n",
    "\n",
    "- The first page of the bookstore is at http://books.toscrape.com/catalogue/page-1.html. Subsequent pages can be found by clicking the \"Next\" button at the bottom of the page. Look at how the URLs change each time you navigate to a new page; think about how to use f-strings (or some other string formatting technique) to generate these URLs.\n",
    "- Use \"inspect element\" to view the source code of the pages you're trying to scrape. To find a book's category, look at the hyperlinks in the book-specific page for that book.\n",
    "- **`scrape_books` should run in under 180 seconds on the entire bookstore (`k = 50`). `scrape_books` is also the only function that should make `GET` requests; the other two functions parse already-existing HTML.**\n",
    "- When instantiating `bs4.BeautifulSoup` objects, use the optional argument `features='lxml'` to suppress any warnings.\n",
    "- Don't worry about typecasting, i.e. it's fine if `'Number of reviews'` is not stored as type `int`. Also, don't worry if you run into encoding errors in your price columns (as the example DataFrame at the top of this cell contains)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe57e11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "2aa83de9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'UPC': 'a492f49a3e2b6a71',\n",
       " 'Product Type': 'Books',\n",
       " 'Price (excl. tax)': 'Â£38.00',\n",
       " 'Price (incl. tax)': 'Â£38.00',\n",
       " 'Tax': 'Â£0.00',\n",
       " 'Availability': 'In stock (1 available)',\n",
       " 'Number of reviews': '0',\n",
       " 'Category': 'Default',\n",
       " 'Rating': 'Two',\n",
       " 'Description': \"Mary Shelley began writing Frankenstein when she was only eighteen. At once a Gothic thriller, a passionate romance, and a cautionary tale about the dangers of science, Frankenstein tells the story of committed science student Victor Frankenstein. Obsessed with discovering the cause of generation and life and bestowing animation upon lifeless matter, Frankenstein assembles Mary Shelley began writing Frankenstein when she was only eighteen. At once a Gothic thriller, a passionate romance, and a cautionary tale about the dangers of science, Frankenstein tells the story of committed science student Victor Frankenstein. Obsessed with discovering the cause of generation and life and bestowing animation upon lifeless matter, Frankenstein assembles a human being from stolen body parts but; upon bringing it to life, he recoils in horror at the creature's hideousness. Tormented by isolation and loneliness, the once-innocent creature turns to evil and unleashes a campaign of murderous revenge against his creator, Frankenstein.Frankenstein, an instant bestseller and an important ancestor of both the horror and science fiction genres, not only tells a terrifying story, but also raises profound, disturbing questions about the very nature of life and the place of humankind within the cosmos: What does it mean to be human? What responsibilities do we have to each other? How far can we go in tampering with Nature? In our age, filled with news of organ donation genetic engineering, and bio-terrorism, these questions are more relevant than ever. ...more\",\n",
       " 'Title': 'Frankenstein'}"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_product_info_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "c75ecd5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\samue\\Desktop\\dsc80-2024-wi\\labs\\lab06\\lab.py:38: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 38 of the file c:\\Users\\samue\\Desktop\\dsc80-2024-wi\\labs\\lab06\\lab.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  soup = bs4.BeautifulSoup(text)\n",
      "c:\\Users\\samue\\Desktop\\dsc80-2024-wi\\labs\\lab06\\lab.py:56: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 56 of the file c:\\Users\\samue\\Desktop\\dsc80-2024-wi\\labs\\lab06\\lab.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  soup = bs4.BeautifulSoup(text)\n"
     ]
    }
   ],
   "source": [
    "# don't delete this cell, but do run it -- it is needed for the autograder tests\n",
    "\n",
    "# public test for extract_book_links \n",
    "extract_book_links_fp = os.path.join('data', 'products.html')\n",
    "extract_book_out = extract_book_links(\n",
    "    open(extract_book_links_fp, encoding='utf-8').read()\n",
    ")\n",
    "extract_book_url = 'scarlet-the-lunar-chronicles-2_218/index.html'\n",
    "\n",
    "# doc tests for get product info\n",
    "get_product_info_fp = os.path.join('data', 'Frankenstein.html')\n",
    "get_product_info_out = get_product_info(\n",
    "    open(get_product_info_fp, encoding='utf-8').read(), ['Default']\n",
    ")\n",
    "\n",
    "# public test for scrape books \n",
    "scrape_books_out = scrape_books(1, ['Mystery'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "7f625a00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UPC</th>\n",
       "      <th>Product Type</th>\n",
       "      <th>Price (excl. tax)</th>\n",
       "      <th>Price (incl. tax)</th>\n",
       "      <th>Tax</th>\n",
       "      <th>Availability</th>\n",
       "      <th>Number of reviews</th>\n",
       "      <th>Category</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Description</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e00eb4fd7b871a48</td>\n",
       "      <td>Books</td>\n",
       "      <td>Ã‚Â£47.82</td>\n",
       "      <td>Ã‚Â£47.82</td>\n",
       "      <td>Ã‚Â£0.00</td>\n",
       "      <td>In stock (20 available)</td>\n",
       "      <td>0</td>\n",
       "      <td>Mystery</td>\n",
       "      <td>Four</td>\n",
       "      <td>WICKED above her hipbone, GIRL across her hear...</td>\n",
       "      <td>Sharp Objects</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                UPC Product Type Price (excl. tax) Price (incl. tax)     Tax  \\\n",
       "0  e00eb4fd7b871a48        Books           Ã‚Â£47.82           Ã‚Â£47.82  Ã‚Â£0.00   \n",
       "\n",
       "              Availability Number of reviews Category Rating  \\\n",
       "0  In stock (20 available)                 0  Mystery   Four   \n",
       "\n",
       "                                         Description          Title  \n",
       "0  WICKED above her hipbone, GIRL across her hear...  Sharp Objects  "
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scrape_books(1, ['Mystery'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "ec80a23b",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q2</pre></strong> passed!</p>"
      ],
      "text/plain": [
       "q2 results: All test cases passed!"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30ae3c1",
   "metadata": {},
   "source": [
    "## Question 3 â€“ API Requests ðŸ¤‘\n",
    "\n",
    "You trade stocks as a hobby. As an avid `pandas` coder, you decide to calculate statistics of your favorite stocks by pulling data from a public API. The API we will work with can be found at https://financialmodelingprep.com/developer/docs/#Stock-Historical-Price. Specifically, we will use the \"**Historical Daily Prices with change and volume interval**\" endpoint (search for it at the linked page).\n",
    "\n",
    "Some relevant definitions:\n",
    "- Ticker: A short code that refers to a stock. For example, Apple's ticker is AAPL and Ford's ticker is F. \n",
    "- Open: The price of a stock at the beginning of a trading day.\n",
    "- Close: The price of a stock at the end of a trading day.\n",
    "- Volume: The total number of shares traded in a day.\n",
    "- Percent change: The difference in price with respect to the original price, as a percentage.\n",
    "\n",
    "To make requests to the aforementioned API, you will need an API key. In order to get one, you will need to make an account at the website. Once you've signed up, you can use the API key that comes with the free plan. It has a limit of 250 requests per day, which should be more than enough. You will have to encode your API key in the URL that you make requests to; see a complete example of such a request at the right side of the [documentation](https://site.financialmodelingprep.com/developer/docs#Stock-Historical-Price).\n",
    "\n",
    "Implement the following two functions.\n",
    "\n",
    "#### `stock_history`\n",
    "\n",
    "Complete the implementation of the function `stock_history`, which takes in a string `ticker` and two integers, `year` and `month`, and returns a DataFrame containing the price history for that stock in that month. Keep all of the attributes that are returned by the API.\n",
    "\n",
    "***Notes***:\n",
    "- Read the API documentation if you get stuck!\n",
    "- [`pd.date_range`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.date_range.html) takes in two dates and returns a sequence of all dates between the two dates, excluding the right endpoint. How might this be helpful?\n",
    "- The [`requests.get`](https://docs.python-requests.org/en/master/user/quickstart/) function returns a Response object, not the data itself. Use the `json` method on the Response object to extract the relevant JSON, as we did in [Lecture 9](https://dsc80.com/resources/lectures/lec09/lec09-filled.html#Example:-GET-requests-via-requests) (you don't need to `import json` to do this).\n",
    "- You can instantiate a DataFrame using a sequence of dictionaries.\n",
    "\n",
    "<br>\n",
    "\n",
    "#### `stock_stats`\n",
    "\n",
    "Create a function `stock_stats` that takes in a DataFrame outputted by `stock_history` and returns a **tuple** of two numbers:\n",
    "1. The percent change of the stock throughout the month as a **percentage**.\n",
    "2. An estimate of the total transaction volume **in billion of dollars** for that month.\n",
    "\n",
    "Both values in the tuple should be **strings** that contain numbers rounded to two decimal places. Add a plus or minus sign in front of the percent change, and make sure that the total transaction volume string ends in a `'B'`.\n",
    "\n",
    "**To compute the percent change**, use the opening price on the first day of the month as the starting price and the closing price on the last day of the month as the ending price.\n",
    "\n",
    "**To compute the total transaction volume**, assume that on any given day, the average price of a share is the midpoint of the high and low price for that day.\n",
    "\n",
    "$$ \\text{Estimated Total Transaction Volume (in dollars)} = \\text{Volume (number of shares traded)} \\times \\text{Average Price} $$\n",
    "\n",
    "For example, suppose there are only three days in March â€“ March 1st, March 2nd, and March 3rd.\n",
    "\n",
    "If BYND (Beyond Meat) opens at \\\\$4 on March 1st and closes at \\\\$5 on March 3rd, its percent change for the month of March is $$\\frac{\\$5-\\$4}{\\$4} = +25.00\\%$$\n",
    "\n",
    "Suppose the high and low prices and volumes of BYND on each day are given below.\n",
    "- March 1st: high \\\\$5, low \\\\$3, volume 500 million (0.5 billion)\n",
    "- March 2nd: high \\\\$5.5, low \\\\$2.5, volume 1 billion\n",
    "- March 3rd: high \\\\$5.25, low \\\\$4, volume 500 million (0.5 billion)\n",
    "\n",
    "Then, the estimated total transaction volume is\n",
    "$$\\frac{\\$5 + \\$3}{2} \\cdot 0.5 B + \\frac{\\$5.5 + \\$2.5}{2} \\cdot 1 B + \\frac{\\$5.25 + \\$4}{2} \\cdot 0.5 B = 8.3125B$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "798ecaf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't delete this cell, but do run it -- it is needed for the autograder tests\n",
    "\n",
    "# public test for stock_history\n",
    "history = stock_history('BYND', 2019, 6)\n",
    "\n",
    "# public test for stock_stats\n",
    "stats = stock_stats(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "d42c1477",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('-54.29%', '1.33 B')"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_stats(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "cc0f2b10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 6)"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(len(stats[0]), len(stats[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "b03db116",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>adjClose</th>\n",
       "      <th>volume</th>\n",
       "      <th>unadjustedVolume</th>\n",
       "      <th>change</th>\n",
       "      <th>changePercent</th>\n",
       "      <th>vwap</th>\n",
       "      <th>label</th>\n",
       "      <th>changeOverTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-06-28</td>\n",
       "      <td>165.30</td>\n",
       "      <td>168.80</td>\n",
       "      <td>159.5500</td>\n",
       "      <td>160.68</td>\n",
       "      <td>160.679993</td>\n",
       "      <td>7315297</td>\n",
       "      <td>7315300</td>\n",
       "      <td>-4.62</td>\n",
       "      <td>-2.79000</td>\n",
       "      <td>163.92</td>\n",
       "      <td>June 28, 19</td>\n",
       "      <td>-0.027900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-06-27</td>\n",
       "      <td>157.31</td>\n",
       "      <td>164.79</td>\n",
       "      <td>155.4500</td>\n",
       "      <td>162.91</td>\n",
       "      <td>162.910004</td>\n",
       "      <td>5719421</td>\n",
       "      <td>5731400</td>\n",
       "      <td>5.60</td>\n",
       "      <td>3.56000</td>\n",
       "      <td>160.43</td>\n",
       "      <td>June 27, 19</td>\n",
       "      <td>0.035600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-06-26</td>\n",
       "      <td>160.10</td>\n",
       "      <td>162.25</td>\n",
       "      <td>153.0200</td>\n",
       "      <td>160.48</td>\n",
       "      <td>160.479996</td>\n",
       "      <td>6378629</td>\n",
       "      <td>6378600</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.23735</td>\n",
       "      <td>157.99</td>\n",
       "      <td>June 26, 19</td>\n",
       "      <td>0.002374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-06-25</td>\n",
       "      <td>138.50</td>\n",
       "      <td>150.69</td>\n",
       "      <td>138.3425</td>\n",
       "      <td>150.60</td>\n",
       "      <td>150.600006</td>\n",
       "      <td>6682929</td>\n",
       "      <td>6632500</td>\n",
       "      <td>12.10</td>\n",
       "      <td>8.74000</td>\n",
       "      <td>146.35</td>\n",
       "      <td>June 25, 19</td>\n",
       "      <td>0.087400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-06-24</td>\n",
       "      <td>151.88</td>\n",
       "      <td>152.70</td>\n",
       "      <td>138.0000</td>\n",
       "      <td>140.99</td>\n",
       "      <td>140.990005</td>\n",
       "      <td>6538497</td>\n",
       "      <td>6538500</td>\n",
       "      <td>-10.89</td>\n",
       "      <td>-7.17000</td>\n",
       "      <td>142.69</td>\n",
       "      <td>June 24, 19</td>\n",
       "      <td>-0.071700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2019-06-21</td>\n",
       "      <td>153.54</td>\n",
       "      <td>161.79</td>\n",
       "      <td>150.0000</td>\n",
       "      <td>154.13</td>\n",
       "      <td>154.130005</td>\n",
       "      <td>7474586</td>\n",
       "      <td>7474600</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.38426</td>\n",
       "      <td>155.01</td>\n",
       "      <td>June 21, 19</td>\n",
       "      <td>0.003843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2019-06-20</td>\n",
       "      <td>173.00</td>\n",
       "      <td>174.00</td>\n",
       "      <td>163.3000</td>\n",
       "      <td>165.17</td>\n",
       "      <td>165.169998</td>\n",
       "      <td>6660492</td>\n",
       "      <td>6660500</td>\n",
       "      <td>-7.83</td>\n",
       "      <td>-4.53000</td>\n",
       "      <td>167.58</td>\n",
       "      <td>June 20, 19</td>\n",
       "      <td>-0.045300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2019-06-19</td>\n",
       "      <td>171.37</td>\n",
       "      <td>174.45</td>\n",
       "      <td>162.2500</td>\n",
       "      <td>169.28</td>\n",
       "      <td>169.279999</td>\n",
       "      <td>9451961</td>\n",
       "      <td>9452000</td>\n",
       "      <td>-2.09</td>\n",
       "      <td>-1.22000</td>\n",
       "      <td>167.61</td>\n",
       "      <td>June 19, 19</td>\n",
       "      <td>-0.012200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2019-06-18</td>\n",
       "      <td>200.00</td>\n",
       "      <td>201.88</td>\n",
       "      <td>160.7000</td>\n",
       "      <td>169.89</td>\n",
       "      <td>169.889999</td>\n",
       "      <td>23966910</td>\n",
       "      <td>23966900</td>\n",
       "      <td>-30.11</td>\n",
       "      <td>-15.06000</td>\n",
       "      <td>175.95</td>\n",
       "      <td>June 18, 19</td>\n",
       "      <td>-0.150600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2019-06-17</td>\n",
       "      <td>163.18</td>\n",
       "      <td>171.19</td>\n",
       "      <td>160.6111</td>\n",
       "      <td>169.96</td>\n",
       "      <td>169.960007</td>\n",
       "      <td>14626683</td>\n",
       "      <td>14626700</td>\n",
       "      <td>6.78</td>\n",
       "      <td>4.15000</td>\n",
       "      <td>166.83</td>\n",
       "      <td>June 17, 19</td>\n",
       "      <td>0.041500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2019-06-14</td>\n",
       "      <td>142.01</td>\n",
       "      <td>157.90</td>\n",
       "      <td>141.8000</td>\n",
       "      <td>151.48</td>\n",
       "      <td>151.479996</td>\n",
       "      <td>14964553</td>\n",
       "      <td>14964600</td>\n",
       "      <td>9.47</td>\n",
       "      <td>6.67000</td>\n",
       "      <td>151.75</td>\n",
       "      <td>June 14, 19</td>\n",
       "      <td>0.066700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2019-06-13</td>\n",
       "      <td>141.52</td>\n",
       "      <td>146.45</td>\n",
       "      <td>134.2500</td>\n",
       "      <td>141.39</td>\n",
       "      <td>141.389999</td>\n",
       "      <td>9474562</td>\n",
       "      <td>9474600</td>\n",
       "      <td>-0.13</td>\n",
       "      <td>-0.09186</td>\n",
       "      <td>141.31</td>\n",
       "      <td>June 13, 19</td>\n",
       "      <td>-0.000919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2019-06-12</td>\n",
       "      <td>133.99</td>\n",
       "      <td>150.45</td>\n",
       "      <td>131.5632</td>\n",
       "      <td>141.97</td>\n",
       "      <td>141.970001</td>\n",
       "      <td>16900631</td>\n",
       "      <td>16918600</td>\n",
       "      <td>7.98</td>\n",
       "      <td>5.96000</td>\n",
       "      <td>140.38</td>\n",
       "      <td>June 12, 19</td>\n",
       "      <td>0.059600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2019-06-11</td>\n",
       "      <td>145.25</td>\n",
       "      <td>150.00</td>\n",
       "      <td>125.2300</td>\n",
       "      <td>126.04</td>\n",
       "      <td>126.040001</td>\n",
       "      <td>15515979</td>\n",
       "      <td>15516000</td>\n",
       "      <td>-19.21</td>\n",
       "      <td>-13.23000</td>\n",
       "      <td>136.34</td>\n",
       "      <td>June 11, 19</td>\n",
       "      <td>-0.132300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2019-06-10</td>\n",
       "      <td>155.70</td>\n",
       "      <td>186.43</td>\n",
       "      <td>147.0000</td>\n",
       "      <td>168.10</td>\n",
       "      <td>168.100006</td>\n",
       "      <td>24978735</td>\n",
       "      <td>24986000</td>\n",
       "      <td>12.40</td>\n",
       "      <td>7.96000</td>\n",
       "      <td>167.94</td>\n",
       "      <td>June 10, 19</td>\n",
       "      <td>0.079600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2019-06-07</td>\n",
       "      <td>130.00</td>\n",
       "      <td>149.46</td>\n",
       "      <td>120.7600</td>\n",
       "      <td>138.65</td>\n",
       "      <td>138.649994</td>\n",
       "      <td>23916747</td>\n",
       "      <td>23916700</td>\n",
       "      <td>8.65</td>\n",
       "      <td>6.65000</td>\n",
       "      <td>132.62</td>\n",
       "      <td>June 07, 19</td>\n",
       "      <td>0.066500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2019-06-06</td>\n",
       "      <td>102.00</td>\n",
       "      <td>102.25</td>\n",
       "      <td>98.8500</td>\n",
       "      <td>99.50</td>\n",
       "      <td>99.500000</td>\n",
       "      <td>6483991</td>\n",
       "      <td>6484000</td>\n",
       "      <td>-2.50</td>\n",
       "      <td>-2.45000</td>\n",
       "      <td>105.64</td>\n",
       "      <td>June 06, 19</td>\n",
       "      <td>-0.024500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2019-06-05</td>\n",
       "      <td>105.50</td>\n",
       "      <td>105.50</td>\n",
       "      <td>99.6400</td>\n",
       "      <td>102.60</td>\n",
       "      <td>102.599998</td>\n",
       "      <td>4283474</td>\n",
       "      <td>4283500</td>\n",
       "      <td>-2.90</td>\n",
       "      <td>-2.75000</td>\n",
       "      <td>102.18</td>\n",
       "      <td>June 05, 19</td>\n",
       "      <td>-0.027500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2019-06-04</td>\n",
       "      <td>101.25</td>\n",
       "      <td>103.50</td>\n",
       "      <td>97.8200</td>\n",
       "      <td>103.41</td>\n",
       "      <td>103.410004</td>\n",
       "      <td>5484873</td>\n",
       "      <td>5484900</td>\n",
       "      <td>2.16</td>\n",
       "      <td>2.13000</td>\n",
       "      <td>100.64</td>\n",
       "      <td>June 04, 19</td>\n",
       "      <td>0.021300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2019-06-03</td>\n",
       "      <td>104.14</td>\n",
       "      <td>108.67</td>\n",
       "      <td>95.6620</td>\n",
       "      <td>96.16</td>\n",
       "      <td>96.160004</td>\n",
       "      <td>8027710</td>\n",
       "      <td>8027700</td>\n",
       "      <td>-7.98</td>\n",
       "      <td>-7.66000</td>\n",
       "      <td>103.12</td>\n",
       "      <td>June 03, 19</td>\n",
       "      <td>-0.076600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          date    open    high       low   close    adjClose    volume  \\\n",
       "0   2019-06-28  165.30  168.80  159.5500  160.68  160.679993   7315297   \n",
       "1   2019-06-27  157.31  164.79  155.4500  162.91  162.910004   5719421   \n",
       "2   2019-06-26  160.10  162.25  153.0200  160.48  160.479996   6378629   \n",
       "3   2019-06-25  138.50  150.69  138.3425  150.60  150.600006   6682929   \n",
       "4   2019-06-24  151.88  152.70  138.0000  140.99  140.990005   6538497   \n",
       "5   2019-06-21  153.54  161.79  150.0000  154.13  154.130005   7474586   \n",
       "6   2019-06-20  173.00  174.00  163.3000  165.17  165.169998   6660492   \n",
       "7   2019-06-19  171.37  174.45  162.2500  169.28  169.279999   9451961   \n",
       "8   2019-06-18  200.00  201.88  160.7000  169.89  169.889999  23966910   \n",
       "9   2019-06-17  163.18  171.19  160.6111  169.96  169.960007  14626683   \n",
       "10  2019-06-14  142.01  157.90  141.8000  151.48  151.479996  14964553   \n",
       "11  2019-06-13  141.52  146.45  134.2500  141.39  141.389999   9474562   \n",
       "12  2019-06-12  133.99  150.45  131.5632  141.97  141.970001  16900631   \n",
       "13  2019-06-11  145.25  150.00  125.2300  126.04  126.040001  15515979   \n",
       "14  2019-06-10  155.70  186.43  147.0000  168.10  168.100006  24978735   \n",
       "15  2019-06-07  130.00  149.46  120.7600  138.65  138.649994  23916747   \n",
       "16  2019-06-06  102.00  102.25   98.8500   99.50   99.500000   6483991   \n",
       "17  2019-06-05  105.50  105.50   99.6400  102.60  102.599998   4283474   \n",
       "18  2019-06-04  101.25  103.50   97.8200  103.41  103.410004   5484873   \n",
       "19  2019-06-03  104.14  108.67   95.6620   96.16   96.160004   8027710   \n",
       "\n",
       "    unadjustedVolume  change  changePercent    vwap        label  \\\n",
       "0            7315300   -4.62       -2.79000  163.92  June 28, 19   \n",
       "1            5731400    5.60        3.56000  160.43  June 27, 19   \n",
       "2            6378600    0.38        0.23735  157.99  June 26, 19   \n",
       "3            6632500   12.10        8.74000  146.35  June 25, 19   \n",
       "4            6538500  -10.89       -7.17000  142.69  June 24, 19   \n",
       "5            7474600    0.59        0.38426  155.01  June 21, 19   \n",
       "6            6660500   -7.83       -4.53000  167.58  June 20, 19   \n",
       "7            9452000   -2.09       -1.22000  167.61  June 19, 19   \n",
       "8           23966900  -30.11      -15.06000  175.95  June 18, 19   \n",
       "9           14626700    6.78        4.15000  166.83  June 17, 19   \n",
       "10          14964600    9.47        6.67000  151.75  June 14, 19   \n",
       "11           9474600   -0.13       -0.09186  141.31  June 13, 19   \n",
       "12          16918600    7.98        5.96000  140.38  June 12, 19   \n",
       "13          15516000  -19.21      -13.23000  136.34  June 11, 19   \n",
       "14          24986000   12.40        7.96000  167.94  June 10, 19   \n",
       "15          23916700    8.65        6.65000  132.62  June 07, 19   \n",
       "16           6484000   -2.50       -2.45000  105.64  June 06, 19   \n",
       "17           4283500   -2.90       -2.75000  102.18  June 05, 19   \n",
       "18           5484900    2.16        2.13000  100.64  June 04, 19   \n",
       "19           8027700   -7.98       -7.66000  103.12  June 03, 19   \n",
       "\n",
       "    changeOverTime  \n",
       "0        -0.027900  \n",
       "1         0.035600  \n",
       "2         0.002374  \n",
       "3         0.087400  \n",
       "4        -0.071700  \n",
       "5         0.003843  \n",
       "6        -0.045300  \n",
       "7        -0.012200  \n",
       "8        -0.150600  \n",
       "9         0.041500  \n",
       "10        0.066700  \n",
       "11       -0.000919  \n",
       "12        0.059600  \n",
       "13       -0.132300  \n",
       "14        0.079600  \n",
       "15        0.066500  \n",
       "16       -0.024500  \n",
       "17       -0.027500  \n",
       "18        0.021300  \n",
       "19       -0.076600  "
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "db537809",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q3</pre></strong> passed!</p>"
      ],
      "text/plain": [
       "q3 results: All test cases passed!"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf3b4b4",
   "metadata": {},
   "source": [
    "## Question 4 â€“ Comment Threads ðŸ§µ\n",
    "\n",
    "You regularly browse [Hacker News](https://news.ycombinator.com/) to keep up with the latest news in tech. One link to a Hacker News article is https://news.ycombinator.com/item?id=18344932. Note that this article has 18 comments and has a `storyid` of 18344932.\n",
    "\n",
    "The problem now is that you don't have internet access on your phone during your morning commute to work, so you want to save the interesting stories' comment threads beforehand in a CSV. You find their [API documentation](https://github.com/HackerNews/API) and decide to get to work.\n",
    "\n",
    "Complete the implementation of the function `get_comments`, which takes in a `storyid` and returns a DataFrame of all the comments below the news story. You can ignore \"dead\" comments(you will know them when you see them), as well as \"dead\" commentsâ€™ children. **Make sure the order of the comments in your DataFrame is from top to bottom just as you see on the website**. \n",
    "\n",
    "The DataFrame that `get_comments` returns should have 5 columns:\n",
    "1. `'id'`: The unique ID of the comment.\n",
    "2. `'by'`: The author of the comment.\n",
    "3. `'text'`: The actual comment.\n",
    "4. `'parent'`: The unique ID of the comment this comment is replying to.\n",
    "5. `'time'`: When the comment was created (in `pd.Timestamp` format).\n",
    "\n",
    "Some guidance:\n",
    "1. The URL to make requests to is `'https://hacker-news.firebaseio.com/v0/item/{}.json'`, however, the `{}` should be replaced with the ID of the article or page you are trying to access. \n",
    "2. Again, do not `import json` â€“ instead, use the `json` method on the Response object you get back.\n",
    "3. Use depth-first search when traversing the comments tree. You will have to do this manually, since you cannot use Beautiful Soup (which is only for HTML documents, not JSON objects).\n",
    "4. Make sure the length of your returned DataFrame is the same as value for the `'descendants'` key in the response JSON (both of which correspond to the number of comments for the story).\n",
    "5. You are allowed to use loops in this function. You may also want to create at least one helper function.\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "    You may find <a href=\"https://www.youtube.com/watch?v=uOfwW-onmpc\"><b>this hint video ðŸŽ¥</b></a> helpful!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "5b1aa407",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>by</th>\n",
       "      <th>text</th>\n",
       "      <th>parent</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18380397</td>\n",
       "      <td>valyala</td>\n",
       "      <td>TimescaleDB is great for storing time series c...</td>\n",
       "      <td>18344932</td>\n",
       "      <td>2018-11-04 22:53:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18346406</td>\n",
       "      <td>msiggy</td>\n",
       "      <td>I&amp;#x27;m excited to give this database a try i...</td>\n",
       "      <td>18344932</td>\n",
       "      <td>2018-10-31 08:20:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18348601</td>\n",
       "      <td>sman393</td>\n",
       "      <td>Can this be used side by side on normal Postgr...</td>\n",
       "      <td>18344932</td>\n",
       "      <td>2018-10-31 12:29:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18348631</td>\n",
       "      <td>RobAtticus</td>\n",
       "      <td>Yep, absolutely. Regular PostgreSQL tables coe...</td>\n",
       "      <td>18348601</td>\n",
       "      <td>2018-10-31 12:34:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18348984</td>\n",
       "      <td>sman393</td>\n",
       "      <td>Good to hear! how does the current TimescaleDB...</td>\n",
       "      <td>18348631</td>\n",
       "      <td>2018-10-31 13:23:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>18349540</td>\n",
       "      <td>RobAtticus</td>\n",
       "      <td>Not sure I follow exactly what you&amp;#x27;re ask...</td>\n",
       "      <td>18348984</td>\n",
       "      <td>2018-10-31 14:47:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>18350673</td>\n",
       "      <td>sman393</td>\n",
       "      <td>Alright thanks! I thought I read that Timescal...</td>\n",
       "      <td>18349540</td>\n",
       "      <td>2018-10-31 18:11:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>18351061</td>\n",
       "      <td>RobAtticus</td>\n",
       "      <td>It does not support sharding writes across mul...</td>\n",
       "      <td>18350673</td>\n",
       "      <td>2018-10-31 19:35:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>18346750</td>\n",
       "      <td>zip1234</td>\n",
       "      <td>How fast is it when it has a TB of data? I rea...</td>\n",
       "      <td>18344932</td>\n",
       "      <td>2018-10-31 08:51:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>18347260</td>\n",
       "      <td>nevi-me</td>\n",
       "      <td>I spent about 8 months writing data to TSDB. I...</td>\n",
       "      <td>18346750</td>\n",
       "      <td>2018-10-31 09:47:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>18347555</td>\n",
       "      <td>dominotw</td>\n",
       "      <td>They have some numbers on their blog. Its very...</td>\n",
       "      <td>18346750</td>\n",
       "      <td>2018-10-31 10:19:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>18346476</td>\n",
       "      <td>dominotw</td>\n",
       "      <td>I evaluated this heavily but had to backoff be...</td>\n",
       "      <td>18344932</td>\n",
       "      <td>2018-10-31 08:27:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>18346702</td>\n",
       "      <td>RobAtticus</td>\n",
       "      <td>Sorry to hear, though I&amp;#x27;d like to mention...</td>\n",
       "      <td>18346476</td>\n",
       "      <td>2018-10-31 08:47:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>18347232</td>\n",
       "      <td>grumpydba</td>\n",
       "      <td>Hi,&lt;p&gt;are the upcoming clustering efforts deve...</td>\n",
       "      <td>18346702</td>\n",
       "      <td>2018-10-31 09:44:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>18349689</td>\n",
       "      <td>jason_slack</td>\n",
       "      <td>What were the specs of the machine you were us...</td>\n",
       "      <td>18346476</td>\n",
       "      <td>2018-10-31 15:16:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>18346746</td>\n",
       "      <td>athenot</td>\n",
       "      <td>It would be nice if they did a quick compariso...</td>\n",
       "      <td>18344932</td>\n",
       "      <td>2018-10-31 08:51:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>18346787</td>\n",
       "      <td>RobAtticus</td>\n",
       "      <td>We do have comparisons, but judging by their M...</td>\n",
       "      <td>18346746</td>\n",
       "      <td>2018-10-31 08:56:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18346822</td>\n",
       "      <td>athenot</td>\n",
       "      <td>Thanks a lot, this is useful for comparing.&lt;p&gt;...</td>\n",
       "      <td>18346787</td>\n",
       "      <td>2018-10-31 09:00:29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id           by                                               text  \\\n",
       "0   18380397      valyala  TimescaleDB is great for storing time series c...   \n",
       "1   18346406       msiggy  I&#x27;m excited to give this database a try i...   \n",
       "2   18348601      sman393  Can this be used side by side on normal Postgr...   \n",
       "3   18348631   RobAtticus  Yep, absolutely. Regular PostgreSQL tables coe...   \n",
       "4   18348984      sman393  Good to hear! how does the current TimescaleDB...   \n",
       "5   18349540   RobAtticus  Not sure I follow exactly what you&#x27;re ask...   \n",
       "6   18350673      sman393  Alright thanks! I thought I read that Timescal...   \n",
       "7   18351061   RobAtticus  It does not support sharding writes across mul...   \n",
       "8   18346750      zip1234  How fast is it when it has a TB of data? I rea...   \n",
       "9   18347260      nevi-me  I spent about 8 months writing data to TSDB. I...   \n",
       "10  18347555     dominotw  They have some numbers on their blog. Its very...   \n",
       "11  18346476     dominotw  I evaluated this heavily but had to backoff be...   \n",
       "12  18346702   RobAtticus  Sorry to hear, though I&#x27;d like to mention...   \n",
       "13  18347232    grumpydba  Hi,<p>are the upcoming clustering efforts deve...   \n",
       "14  18349689  jason_slack  What were the specs of the machine you were us...   \n",
       "15  18346746      athenot  It would be nice if they did a quick compariso...   \n",
       "16  18346787   RobAtticus  We do have comparisons, but judging by their M...   \n",
       "17  18346822      athenot  Thanks a lot, this is useful for comparing.<p>...   \n",
       "\n",
       "      parent                time  \n",
       "0   18344932 2018-11-04 22:53:19  \n",
       "1   18344932 2018-10-31 08:20:22  \n",
       "2   18344932 2018-10-31 12:29:39  \n",
       "3   18348601 2018-10-31 12:34:52  \n",
       "4   18348631 2018-10-31 13:23:46  \n",
       "5   18348984 2018-10-31 14:47:20  \n",
       "6   18349540 2018-10-31 18:11:59  \n",
       "7   18350673 2018-10-31 19:35:03  \n",
       "8   18344932 2018-10-31 08:51:43  \n",
       "9   18346750 2018-10-31 09:47:34  \n",
       "10  18346750 2018-10-31 10:19:34  \n",
       "11  18344932 2018-10-31 08:27:29  \n",
       "12  18346476 2018-10-31 08:47:41  \n",
       "13  18346702 2018-10-31 09:44:39  \n",
       "14  18346476 2018-10-31 15:16:27  \n",
       "15  18344932 2018-10-31 08:51:13  \n",
       "16  18346746 2018-10-31 08:56:39  \n",
       "17  18346787 2018-10-31 09:00:29  "
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_comments(18344932)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "c47bfce4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>by</th>\n",
       "      <th>text</th>\n",
       "      <th>parent</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18380397</td>\n",
       "      <td>valyala</td>\n",
       "      <td>TimescaleDB is great for storing time series c...</td>\n",
       "      <td>18344932</td>\n",
       "      <td>2018-11-04 22:53:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18346406</td>\n",
       "      <td>msiggy</td>\n",
       "      <td>I&amp;#x27;m excited to give this database a try i...</td>\n",
       "      <td>18344932</td>\n",
       "      <td>2018-10-31 08:20:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18348601</td>\n",
       "      <td>sman393</td>\n",
       "      <td>Can this be used side by side on normal Postgr...</td>\n",
       "      <td>18344932</td>\n",
       "      <td>2018-10-31 12:29:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18348631</td>\n",
       "      <td>RobAtticus</td>\n",
       "      <td>Yep, absolutely. Regular PostgreSQL tables coe...</td>\n",
       "      <td>18348601</td>\n",
       "      <td>2018-10-31 12:34:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18348984</td>\n",
       "      <td>sman393</td>\n",
       "      <td>Good to hear! how does the current TimescaleDB...</td>\n",
       "      <td>18348631</td>\n",
       "      <td>2018-10-31 13:23:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>18349540</td>\n",
       "      <td>RobAtticus</td>\n",
       "      <td>Not sure I follow exactly what you&amp;#x27;re ask...</td>\n",
       "      <td>18348984</td>\n",
       "      <td>2018-10-31 14:47:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>18350673</td>\n",
       "      <td>sman393</td>\n",
       "      <td>Alright thanks! I thought I read that Timescal...</td>\n",
       "      <td>18349540</td>\n",
       "      <td>2018-10-31 18:11:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>18351061</td>\n",
       "      <td>RobAtticus</td>\n",
       "      <td>It does not support sharding writes across mul...</td>\n",
       "      <td>18350673</td>\n",
       "      <td>2018-10-31 19:35:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>18346750</td>\n",
       "      <td>zip1234</td>\n",
       "      <td>How fast is it when it has a TB of data? I rea...</td>\n",
       "      <td>18344932</td>\n",
       "      <td>2018-10-31 08:51:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>18347260</td>\n",
       "      <td>nevi-me</td>\n",
       "      <td>I spent about 8 months writing data to TSDB. I...</td>\n",
       "      <td>18346750</td>\n",
       "      <td>2018-10-31 09:47:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>18347555</td>\n",
       "      <td>dominotw</td>\n",
       "      <td>They have some numbers on their blog. Its very...</td>\n",
       "      <td>18346750</td>\n",
       "      <td>2018-10-31 10:19:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>18346476</td>\n",
       "      <td>dominotw</td>\n",
       "      <td>I evaluated this heavily but had to backoff be...</td>\n",
       "      <td>18344932</td>\n",
       "      <td>2018-10-31 08:27:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>18346702</td>\n",
       "      <td>RobAtticus</td>\n",
       "      <td>Sorry to hear, though I&amp;#x27;d like to mention...</td>\n",
       "      <td>18346476</td>\n",
       "      <td>2018-10-31 08:47:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>18347232</td>\n",
       "      <td>grumpydba</td>\n",
       "      <td>Hi,&lt;p&gt;are the upcoming clustering efforts deve...</td>\n",
       "      <td>18346702</td>\n",
       "      <td>2018-10-31 09:44:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>18349689</td>\n",
       "      <td>jason_slack</td>\n",
       "      <td>What were the specs of the machine you were us...</td>\n",
       "      <td>18346476</td>\n",
       "      <td>2018-10-31 15:16:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>18346746</td>\n",
       "      <td>athenot</td>\n",
       "      <td>It would be nice if they did a quick compariso...</td>\n",
       "      <td>18344932</td>\n",
       "      <td>2018-10-31 08:51:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>18346787</td>\n",
       "      <td>RobAtticus</td>\n",
       "      <td>We do have comparisons, but judging by their M...</td>\n",
       "      <td>18346746</td>\n",
       "      <td>2018-10-31 08:56:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18346822</td>\n",
       "      <td>athenot</td>\n",
       "      <td>Thanks a lot, this is useful for comparing.&lt;p&gt;...</td>\n",
       "      <td>18346787</td>\n",
       "      <td>2018-10-31 09:00:29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id           by                                               text  \\\n",
       "0   18380397      valyala  TimescaleDB is great for storing time series c...   \n",
       "1   18346406       msiggy  I&#x27;m excited to give this database a try i...   \n",
       "2   18348601      sman393  Can this be used side by side on normal Postgr...   \n",
       "3   18348631   RobAtticus  Yep, absolutely. Regular PostgreSQL tables coe...   \n",
       "4   18348984      sman393  Good to hear! how does the current TimescaleDB...   \n",
       "5   18349540   RobAtticus  Not sure I follow exactly what you&#x27;re ask...   \n",
       "6   18350673      sman393  Alright thanks! I thought I read that Timescal...   \n",
       "7   18351061   RobAtticus  It does not support sharding writes across mul...   \n",
       "8   18346750      zip1234  How fast is it when it has a TB of data? I rea...   \n",
       "9   18347260      nevi-me  I spent about 8 months writing data to TSDB. I...   \n",
       "10  18347555     dominotw  They have some numbers on their blog. Its very...   \n",
       "11  18346476     dominotw  I evaluated this heavily but had to backoff be...   \n",
       "12  18346702   RobAtticus  Sorry to hear, though I&#x27;d like to mention...   \n",
       "13  18347232    grumpydba  Hi,<p>are the upcoming clustering efforts deve...   \n",
       "14  18349689  jason_slack  What were the specs of the machine you were us...   \n",
       "15  18346746      athenot  It would be nice if they did a quick compariso...   \n",
       "16  18346787   RobAtticus  We do have comparisons, but judging by their M...   \n",
       "17  18346822      athenot  Thanks a lot, this is useful for comparing.<p>...   \n",
       "\n",
       "      parent                time  \n",
       "0   18344932 2018-11-04 22:53:19  \n",
       "1   18344932 2018-10-31 08:20:22  \n",
       "2   18344932 2018-10-31 12:29:39  \n",
       "3   18348601 2018-10-31 12:34:52  \n",
       "4   18348631 2018-10-31 13:23:46  \n",
       "5   18348984 2018-10-31 14:47:20  \n",
       "6   18349540 2018-10-31 18:11:59  \n",
       "7   18350673 2018-10-31 19:35:03  \n",
       "8   18344932 2018-10-31 08:51:43  \n",
       "9   18346750 2018-10-31 09:47:34  \n",
       "10  18346750 2018-10-31 10:19:34  \n",
       "11  18344932 2018-10-31 08:27:29  \n",
       "12  18346476 2018-10-31 08:47:41  \n",
       "13  18346702 2018-10-31 09:44:39  \n",
       "14  18346476 2018-10-31 15:16:27  \n",
       "15  18344932 2018-10-31 08:51:13  \n",
       "16  18346746 2018-10-31 08:56:39  \n",
       "17  18346787 2018-10-31 09:00:29  "
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_comments(18344932)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "c2d5ba6a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# don't delete this cell, but do run it -- it is needed for the autograder tests\n",
    "comments = get_comments(18344932)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "7de748c3",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q4</pre></strong> passed!</p>"
      ],
      "text/plain": [
       "q4 results: All test cases passed!"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba30a02c",
   "metadata": {},
   "source": [
    "## Congratulations! You're done Lab 6! ðŸ\n",
    "\n",
    "As a reminder, all of the work you want to submit needs to be in `lab.py`.\n",
    "\n",
    "To ensure that all of the work you want to submit is in `lab.py`, we've included a script named `lab-validation.py` in the lab folder. You shouldn't edit it, but instead, you should call it from the command line (e.g. the Terminal) to test your work.\n",
    "\n",
    "Once you've finished the lab, you should open the command line and run, in the directory for this lab:\n",
    "\n",
    "```\n",
    "python lab-validation.py\n",
    "```\n",
    "\n",
    "**This will run all of the `grader.check` cells that you see in this notebook, but only using the code in `lab.py` â€“ that is, it doesn't look at any of the code in this notebook. If all of your `grader.check` cells pass in this notebook but not all of them pass in your command line with the above command, then you likely have code in your notebook that isn't in your `lab.py`!**\n",
    "\n",
    "You can also use `lab-validation.py` to test individual questions. For instance,\n",
    "\n",
    "```\n",
    "python lab-validation.py q1 q2 q4\n",
    "```\n",
    "\n",
    "will run the `grader.check` cells for Questions 1, 2, and 4 â€“ again, only using the code in `lab.py`. [This video](https://www.loom.com/share/0ea254b85b2745e59322b5e5a8692e91?sid=5acc92e6-0dfe-4555-9b6a-8115b6a52f99) how to use the script as well.\n",
    "\n",
    "Once `python lab-validation.py` shows that you're passing all test cases, you're ready to submit your `lab.py` (and only your `lab.py`) to Gradescope. Once submitting to Gradescope, make sure to stick around until all test cases pass.\n",
    "\n",
    "There is also a call to `grader.check_all()` below in _this_ notebook, but make sure to also follow the steps above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf55f504",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "\n",
    "To double-check your work, the cell below will rerun all of the autograder tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "17520389",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "q1 results: All test cases passed!\n",
       "\n",
       "q2 results: All test cases passed!\n",
       "\n",
       "q3 results: All test cases passed!\n",
       "\n",
       "q4 results: All test cases passed!"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check_all()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "otter": {
   "tests": {
    "q1": {
     "name": "q1",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> os.path.exists('lab06_1.html')\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> q01_html = bs4.BeautifulSoup(open(\"lab06_1.html\", encoding='utf-8'))\n>>> len(q01_html.find_all('image')) == 0\nTrue",
         "failure_message": "you should not use the <image> tag to add images",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2": {
     "name": "q2",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> extract_book_out[1] == extract_book_url\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> isinstance(get_product_info_out, dict)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> 'Category' in get_product_info_out.keys()\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> get_product_info_out['Rating'] == 'Two'\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> scrape_books_out.shape == (1, 11)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> scrape_books_out['Rating'][0] == 'Four'\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> scrape_books_out['Title'][0] == 'Sharp Objects'\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3": {
     "name": "q3",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> history.shape == (20, 13)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> history.label.iloc[-1] == 'June 03, 19'\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> (len(stats[0]), len(stats[1])) == (7, 6)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> (float(stats[0][1:-1]) > 30) == True\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> float(stats[1][:-1]) > 1 == True\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> stats[1][-1] == 'B'\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4": {
     "name": "q4",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> comments.shape == (18, 5)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> comments.loc[5, 'by'] == 'RobAtticus'\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> comments.loc[5, 'time'].day == 31\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
